# Multi-GPU training example

This example uses a CNN implemented in PyTorch to demonstrate how one might parallelize model training across several GPUs on a single node. Note that this is a different problem than  spreading the model across multiple GPUs, as might be required when training very large models that cannot fit in the memory of a single GPU. Moreover, this example demonstrates that multi-GPU training does not necessarily lead to speedups in training, and some thought should be given to whether a model will benefit from parallel training, as well as how that parallelism is implemented. 

## Single GPU Training

The directory called ```one``` demonstrates a model implemented to train on a single node, single GPU. To run this example, navigate into the directory using ```cd one/```. There should be three files:

- ```model.py``` -- A PyTorch implementation of a CNN that trains on CIFAR10 for 10 epochs. This model does not implement any GPU parallelism, as it's meant to serve as a baseline against which to compare parallel implementations.

- ```run.sh``` -- The run file used by HTCondor to set up the job's conda environment and run ```model.py```.

- ```submit.sub``` -- The submit file used by HTCondor for job submission.

To run the job in CHTC, run ```condor_submit submit.sub``` from your terminal. This will add the job to the queue.

Upon completion of the job, several additional files will be generated:

- ```job_1.log``` -- The HTCondor log file generated by this job.

- ```err_1.err``` -- The job's stderr output.

- ```out_1.out``` -- The job's stdout output. This file will print the time taken by the model training loop on one GPU and can be compared to the output files for the other tests.

- ```model_with_epoch[number].pth``` -- Model checkpoints generated by PyTorch. These files can be ignored.

## Multi-GPU Training

The directories called ```two``` and ```four``` demonstrate models implemented to train on a single node with either two or four GPUs, respectively. To run these examples, navigate into their directories as in the single GPU example. Again, there should be three files, including a model file with ```.py``` extension, a run file with ```.sh``` extension, and a submit file with ```.sub``` extension.


To run either job in CHTC, run ```condor_submit [submit_file].sub``` from your terminal, where ```[submit_file].sub``` is the name of the submit file in the directory. This will add the job to the queue.

Upon completion of the job, three additional files will be generated, similar to the single GPU example. These include a job log with ```.log``` extension, an error file with ```.err``` extension, an output file with ```.out``` extension, and the model checkpoints with ```.pth``` extension.

To compare model training times, compare the times listed in the output files. The two/four GPU jobs should take more time than the single GPU job, as this example demonstrates an inefficient approach to parallelization. 

## Additional Files

- ```env.yml``` -- This file contains setup information for the conda environment needed by each job.

- ```http://proxy.chtc.wisc.edu/SQUID/gpu-examples/Miniconda3-latest-Linux-x86_64.sh``` -- The conda installation file located in the gpu-examples Squid directory.