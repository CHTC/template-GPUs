universe = vanilla

log = job_$(Cluster)_$(Process).log

executable = run_parallel.sh
arguments = $(request_gpus)

output = out_$(Cluster)_$(Process).out
error = err_$(Cluster)_$(Process).err

should_transfer_files = YES
when_to_transfer_output = ON_EXIT
transfer_input_files = http://proxy.chtc.wisc.edu/SQUID/gpu-examples/Miniconda3-latest-Linux-x86_64.sh, env.yml, model_parallel.py

# To demonstrate multi-GPU jobs, restrict them to run only on a limited
# set of GPUs with a specific compute capability
# Research multi-GPU jobs would typically use a larger range of GPUs
require_gpus = (Capability == 7.5) && (DriverVersion >= 11.3)
request_cpus = 4

# Edit how many GPUs are requested on the next line
request_gpus = 1
request_memory = 48GB
request_disk = 40GB

requirements = (OpSysMajorVer==7 || OpSysMajorVer==8)

+WantGPULab = true
+GPUJobLength = "short"

queue 1
