JobBatchName            = "LLM training template"
# Update your run name here and whether to use wandb
arguments               = demo_run --use_wandb

universe                = docker
docker_image            = ghcr.io/jasonlo/chtc_condor:latest
docker_network_type     = host

# Artefact
Requirements            = (Target.HasCHTCStaging == true)
executable              = run.sh
transfer_input_files    = train.py, .env
should_transfer_files   = YES

# Checkpoint
checkpoint_exit_code    = 85
+is_resumable           = true

# Logging
stream_output           = true
output                  = condor_log/output.$(Cluster)-$(Process).txt
error                   = condor_log/error.$(Cluster)-$(Process).txt
log                     = condor_log/log.$(Cluster)-$(Process).txt

# Compute resources
request_cpus            = 2
request_memory          = 8GB
request_disk            = 100GB

# Extra GPU settings
request_gpus            = 2
Requirements            = (Target.CUDADriverVersion >= 10.1)
+WantGPULab             = true
# change to true if *not* using staging for checkpoints and interested in accessing GPUs beyond CHTC
+WantFlocking           = false
+WantGlidein            = false
+GPUJobLength           = "short"

# Runs
queue 1