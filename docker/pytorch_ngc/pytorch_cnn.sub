# PyTorch test of convolutional neural network
# Submit file 

# Must set the universe to Docker
universe = docker
# Use the PyTorch container from the NVIDIA GPU Cloud (NGC)
docker_image = nvcr.io/nvidia/pytorch:20.06-py3

# set the log, error and output files 
log = pytorch_cnn.log.txt
error = pytorch_cnn.err.txt
output = pytorch_cnn.out.txt

# set the executable to run
executable = pytorch_cnn.sh
arguments = $(Process)

# take our python script to the compute node
# the script and data are shared by multiple examples and located in a
# different directory
transfer_input_files = ../../shared/pytorch/main.py, ../../shared/pytorch/MNIST_data.tar.gz

should_transfer_files = YES
when_to_transfer_output = ON_EXIT

# We require a machine with a modern version of the CUDA driver
Requirements = (Target.CUDADriverVersion >= 11.0)

# We must request 1 CPU in addition to 1 GPU
request_cpus = 1
request_gpus = 1

# select some memory and disk space
request_memory = 3GB
request_disk = 15GB

# Opt in to using CHTC GPU Lab resources
+WantGPULab = true
# Specify short job type to run more GPUs in parallel
# Can also request "medium" or "long"
+GPUJobLength = "short"

# Tell HTCondor to run 1 instances of our job:
queue 1
